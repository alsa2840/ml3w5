{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5498ddd",
   "metadata": {},
   "source": [
    "# ML3 Week 5 — Monet Style Transfer Mini‑Project (Deliverable 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b4237b",
   "metadata": {},
   "source": [
    "Short problem/data description → EDA → model building → training stub → results → conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b80c5bd",
   "metadata": {},
   "source": [
    "## Setup & Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9339b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, glob, random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "MONET_DIR = r\"C:\\Users\\Almog\\Desktop\\monet_jpg\"\n",
    "PHOTO_DIR = r\"C:\\Users\\Almog\\Desktop\\photo_jpg\"\n",
    "IMG_SIZE = 256\n",
    "\n",
    "assert os.path.isdir(MONET_DIR), f\"Missing: {MONET_DIR}\"\n",
    "monet_files = sorted(glob.glob(os.path.join(MONET_DIR, \"*.jpg\"))\n",
    "                     + glob.glob(os.path.join(MONET_DIR, \"*.jpeg\"))\n",
    "                     + glob.glob(os.path.join(MONET_DIR, \"*.png\")))\n",
    "photo_files = []\n",
    "if os.path.isdir(PHOTO_DIR):\n",
    "    photo_files = sorted(glob.glob(os.path.join(PHOTO_DIR, \"*.jpg\"))\n",
    "                         + glob.glob(os.path.join(PHOTO_DIR, \"*.jpeg\"))\n",
    "                         + glob.glob(os.path.join(PHOTO_DIR, \"*.png\")))\n",
    "SKIP_TRAINING = (len(photo_files) == 0)\n",
    "print(\"Monet:\", len(monet_files), \"Photos:\", len(photo_files))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9446dc",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc79bfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show(paths, title, n=6):\n",
    "    n = min(n, len(paths))\n",
    "    if n == 0:\n",
    "        print(\"No images:\", title); return\n",
    "    s = random.sample(paths, n)\n",
    "    rows, cols = 2, (n + 1)//2\n",
    "    plt.figure(figsize=(3*cols, 3*rows))\n",
    "    for i,p in enumerate(s):\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        img = Image.open(p).convert(\"RGB\")\n",
    "        plt.imshow(img); plt.axis(\"off\")\n",
    "    plt.suptitle(title); plt.tight_layout(); plt.show()\n",
    "\n",
    "show(monet_files, \"Monet samples\")\n",
    "if not SKIP_TRAINING:\n",
    "    show(photo_files, \"Photo samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfca4a6",
   "metadata": {},
   "source": [
    "## Model (compact CycleGAN blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090e6b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_tf_image(path):\n",
    "    x = tf.io.read_file(path)\n",
    "    x = tf.image.decode_image(x, channels=3, expand_animations=False)\n",
    "    x = tf.image.resize(x, [IMG_SIZE, IMG_SIZE], method='area')\n",
    "    x = tf.cast(x, tf.float32)/127.5 - 1.0\n",
    "    return x\n",
    "\n",
    "class ReflectionPad2D(tf.keras.layers.Layer):\n",
    "    def __init__(self, pad): super().__init__(); self.pad=pad\n",
    "    def call(self, x): p=self.pad; return tf.pad(x, [[0,0],[p,p],[p,p],[0,0]], mode=\"REFLECT\")\n",
    "\n",
    "def conv_blk(x,f,k=3,s=1,norm=True,act=True):\n",
    "    x = tf.keras.layers.Conv2D(f,k,s,padding='valid' if k==7 else 'same',use_bias=not norm)(x)\n",
    "    if norm:\n",
    "        m,v = tf.nn.moments(x,[1,2],keepdims=True)\n",
    "        x = (x-m)/tf.sqrt(v+1e-5)\n",
    "    if act: x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def res_block(x,f):\n",
    "    y = ReflectionPad2D(1)(x)\n",
    "    y = conv_blk(y,f,3,1,True,True)\n",
    "    y = ReflectionPad2D(1)(y)\n",
    "    y = conv_blk(y,f,3,1,True,False)\n",
    "    return tf.keras.layers.Add()([x,y])\n",
    "\n",
    "def build_generator(img_size=256,n_res=6):\n",
    "    i = tf.keras.Input((img_size,img_size,3))\n",
    "    x = ReflectionPad2D(3)(i)\n",
    "    x = conv_blk(x,64,7,1)\n",
    "    x = conv_blk(x,128,3,2)\n",
    "    x = conv_blk(x,256,3,2)\n",
    "    for _ in range(n_res): x = res_block(x,256)\n",
    "    x = tf.keras.layers.Conv2DTranspose(128,3,2,padding=\"same\")(x); x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.Conv2DTranspose(64,3,2,padding=\"same\")(x);  x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = ReflectionPad2D(3)(x)\n",
    "    o = tf.keras.layers.Conv2D(3,7,padding=\"valid\",activation=\"tanh\")(x)\n",
    "    return tf.keras.Model(i,o)\n",
    "\n",
    "def build_discriminator(img_size=256):\n",
    "    def d(x,f,s): x=tf.keras.layers.Conv2D(f,4,s,padding=\"same\")(x); return tf.keras.layers.LeakyReLU(0.2)(x)\n",
    "    i = tf.keras.Input((img_size,img_size,3))\n",
    "    x = d(i,64,2); x=d(x,128,2); x=d(x,256,2); x=d(x,512,1)\n",
    "    o = tf.keras.layers.Conv2D(1,4,padding=\"same\")(x)\n",
    "    return tf.keras.Model(i,o)\n",
    "\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "mae = tf.keras.losses.MeanAbsoluteError()\n",
    "def gan_loss(logits, is_real):\n",
    "    y = tf.ones_like(logits) if is_real else tf.zeros_like(logits)\n",
    "    return mse(y, logits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af10c457",
   "metadata": {},
   "source": [
    "## Training (auto‑skip if `photo_jpg` missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d607a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH=4; EPOCHS=3; STEPS=300\n",
    "\n",
    "def ds_from(paths):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(paths)\n",
    "    ds = ds.shuffle(1000, reshuffle_each_iteration=True)\n",
    "    ds = ds.map(lambda p: load_tf_image(p), num_parallel_calls=tf.data.AUTOTUNE).batch(BATCH)\n",
    "    return ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "if SKIP_TRAINING:\n",
    "    print(\"Training skipped: no photos in\", PHOTO_DIR)\n",
    "else:\n",
    "    photo_ds = ds_from(photo_files); monet_ds = ds_from(monet_files)\n",
    "    paired = tf.data.Dataset.zip((photo_ds, monet_ds))\n",
    "\n",
    "    G = build_generator(); F = build_generator()\n",
    "    Dx = build_discriminator(); Dy = build_discriminator()\n",
    "    opt = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "    LAMBDA_CYCLE=10.0; LAMBDA_ID=0.5\n",
    "\n",
    "    @tf.function\n",
    "    def step(rx, ry):\n",
    "        with tf.GradientTape(persistent=True) as t:\n",
    "            fy = G(rx, training=True); cx = F(fy, training=True)\n",
    "            fx = F(ry, training=True); cy = G(fx, training=True)\n",
    "            sx = F(rx, training=True); sy = G(ry, training=True)\n",
    "            dxr = Dx(rx, True); dxf = Dx(fx, True)\n",
    "            dyr = Dy(ry, True); dyf = Dy(fy, True)\n",
    "            g_adv = gan_loss(dyf, True); f_adv = gan_loss(dxf, True)\n",
    "            cyc = mae(rx, cx)+mae(ry, cy); idt = mae(rx, sx)+mae(ry, sy)\n",
    "            g_tot = g_adv + LAMBDA_CYCLE*cyc + LAMBDA_ID*idt\n",
    "            f_tot = f_adv + LAMBDA_CYCLE*cyc + LAMBDA_ID*idt\n",
    "            dx_loss = 0.5*(gan_loss(dxr, True)+gan_loss(dxf, False))\n",
    "            dy_loss = 0.5*(gan_loss(dyr, True)+gan_loss(dyf, False))\n",
    "        for net,gr in [(G,t.gradient(g_tot,G.trainable_variables)),\n",
    "                       (F,t.gradient(f_tot,F.trainable_variables)),\n",
    "                       (Dx,t.gradient(dx_loss,Dx.trainable_variables)),\n",
    "                       (Dy,t.gradient(dy_loss,Dy.trainable_variables))]:\n",
    "            opt.apply_gradients(zip(gr, net.trainable_variables))\n",
    "        return g_tot, f_tot, dx_loss, dy_loss\n",
    "\n",
    "    it = iter(paired.repeat())\n",
    "    for e in range(EPOCHS):\n",
    "        for s in range(STEPS):\n",
    "            gL,fL,dxL,dyL = step(*next(it))\n",
    "        print(f\"Epoch {e+1}: G {gL.numpy():.3f} F {fL.numpy():.3f} Dx {dxL.numpy():.3f} Dy {dyL.numpy():.3f}\")\n",
    "    import os\n",
    "    os.makedirs(\"weights\", exist_ok=True)\n",
    "    G.save(\"weights/photo2monet_generator.keras\")\n",
    "    print(\"Saved weights to weights/photo2monet_generator.keras\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b0b817",
   "metadata": {},
   "source": [
    "## Results & Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8d308f",
   "metadata": {},
   "source": [
    "Provided results in github, you can look. cant upload it here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a373b0ae",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
